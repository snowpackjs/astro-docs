---
title: Incremental Static Regeneration
---
If your website fetches content from a CMS or a database that updates infrequently, you can use a technique called **Incremental Static Regeneration**, or ISR, to update your site without rebuilding the entire project. This is a great way to keep your site up-to-date while still enjoying the benefits of static hosting.

:::note
ISR is often presented as an alternative to SSG and SSR, but it's more helpful to think of it as SSR with caching.
:::

:::note
Incremental static regeneration is different from **incremental builds**, which speeds up full rebuilds by reusing work done by the previous builds.
:::

## Why ISR?
- Your site has a lot of pages (more than one thousand). Build times can be shortened when using SSR or ISR.
- Your content changes infrequently (less frequently than once in 5 minutes on average).
- Your site gets a lot of visitors. It can be wasteful to render the same page for every visitor, and you can avoid it using ISR.
- The CMS or database you are using is slow, or charges by request. With ISR, the requests to your backend will become much less frequent.

## Why not ISR?
- Your content is located inside your project (for example, as markdown files in `src/content`).
- You don't want the hassle of running a server or using a serverless platform.
- Your website offers logged-in experiences. If each user needs to be sent a slightly different HTML from others, caching the page may not be possible.
- The structure of your site (layouts, and styling) changes frequently. Changes to the structure require a full rebuild.

## About Cache-Control Headers
You will see `Cache-Control` headers being used for many of the platforms below. It is worth reviewing the basics of how they work.
 - `Cache-Control: s-maxage=60` tells the caching server to cache the response for 60 seconds. You probably want to use this for most cases.
 - `Cache-Control: max-age=60` tells both browsers and servers to cache the response for 60 seconds. You may use this when your content is unlikely to be edited. If a page with `max-age` updates after it has been visited by a user, their browser will show them the cached version until the age of the content is past `max-age`.
 - `Cache-Control: private, max-age=60` tells the browser to cache the response for 60 seconds, but not to cache it on any server. This is useful to provide quick navigation, and the content includes details specific to the visitor.

## Implementing ISR for Your Project

ISR involves saving the response such that it can be reused for future requests. The exact implementation depends on where you are deploying. If you aren't already using an adapter already, you are going to need to add one. See the [integrations guide](/en/guides/integrations-guide/) for specific instructions. In your config, make sure that the "output" is either "server" or "hybrid". If it is "hybrid", the pages you want generated, cached, and invalidated will need to be opted-out of prerendering. See the [server side rendering guide](/en/guides/server-side-rendering/#opting-out-of-pre-rendering) to see how.

### Self-hosted Node.js
ISR can be implemented in Node.js by writing a caching middleware. The following middleware caches the response in memory for 60 seconds:

```ts title="src/middleware.ts"

const cache = {}

export const onRequest = async ({ request }, next) => {
    const cached = cache[request.url]
    
    if (cached) {
        if (cached.expires > Date.now()) {
            // return cached response
            return cached.response.clone()
        }
        else {
            // remove stale response
            delete cache[request.url]
        }
    }
    
    const response = await next()
    cache[request.url] = {
        expires: Date.now() + 60 * 1000,
        response: response.clone()
    }
    // return fresh response
    return response

}
```

### Node.js on AWS Lambda
Lambda instances are ephemeral, which means they might lose all state between invocation - on-disk and in-memory.
:::note
TODO: Investigate disk mounts
:::

### Self-hosted Deno
The middleware approach used for Node will work on Deno. However, Deno also implements the Web Cache API that can persist the cache across restarts. The following middleware uses the Web Cache API to cache responses for 60 seconds:

```ts title="src/middleware.ts"

const cache = await caches.open('astro')

export const onRequest = async ({ request }, next) => {
    const cachedResponse = await cache.match(request)
    
    if (cachedResponse) {
        const expires = Number(cachedResponse.headers.get('X-expires'))
        if (expires > Date.now()) {
            // return cached response
            return cachedResponse
        }
        else {
            // remove stale response
            await cache.delete(request)
        }
    }
    
    const response = await next()
    
    // set expiry
    response.headers.set('X-expires', String(Date.now() + 60 * 1000))

    await cache.put(request.url, response.clone())
    // return fresh response
    return response
}
```

### Deno Deploy
Deno Deploy does not provide a way to persist data. However, you may be able to use a third-party caching database to manually cache responses. While this avoids calls to your CMS, you may still experience significant latencies due to the network round-trip time between the Deno Deploy instance and your database.

### Vercel
Vercel provides a built-in caching layer that automatically saves cacheable responses. Make sure your server-rendered page or endpoint sets a `Cache-Control` header.

```astro title="src/pages/index.astro"
---
Astro.response.headers.set('Cache-Control', 's-maxage=60')
---
<h1>Welcome to Astro</h1>
```

```ts title="src/pages/api.ts"
export async function get({ params, request }) {
    ...
    return new Response(content, {
        headers: { "Cache-Control": "s-maxage=60" }
    })
}
```
Vercel only supports `s-maxage` and `stale-while-revalidate` in the Cache-Control header. See [vercel documentation](https://vercel.com/docs/concepts/edge-network/caching) for current information.

### Netlify
Netlify supports caching via two methods: `Cache-Control` headers, which works with edge and serverless functions; and, On-demand Builders, a type of function dedicated for optimized caching.

#### On-demand Builders
On-demand Builders are serverless functions used to generate web content as needed that’s automatically cached on Netlify’s Edge CDN. They enable you to build 
To enable them, set the `builders` option to `true` in your config file.
```ts title="stro.config.js" ins={6}
import { defineConfig } from 'astro/config'
import netlify from '@astrojs/netlify/functions'

export default defineConfig({
  output: 'server',
  adapter: netlify({ builders: true })
})
```
By default, pages for your site will be built when a user visits them for the first time and then cached at the edge for subsequent visits. To set a revalidation time, call the `runtime.setBuildersTtl(ttl)` local with the duration (in seconds). For example, to set a revalidation time of 60 seconds:
```ts title="src/pages/index.astro"
---
Astro.locals.runtime.setBuildersTtl(60)
---
<h1>Welcome to Astro</h1>
```
TODO: middleware equivalent
When you set a revalidation time, Netlify will rerender the page in the background at regular intervals so that visitors never have to wait for a page to be rendered.
It is important to note that On-demand Builders ignore query params when checking for cached pages. For example, if `example.com/?x=y` is cached, it will be served for `example.com/?a=b` (different query params) and `example.com/` (no query params) as well.
See Netlify's [documentation](https://docs.netlify.com/configure-builds/on-demand-builders) to learn more about On-demand Builders.

#### Edge and serverless functions
Netlify supports caching via `Cache-Control` headers. Make sure your server-rendered page or endpoint sets a `Cache-Control` header.

```astro title="src/pages/index.astro"
---
Astro.response.headers.set('Cache-Control', 's-maxage=60')
---
<h1>Welcome to Astro</h1>
```

See [Netlify's documentation](https://docs.netlify.com/edge-functions/optional-configuration/#supported-headers) on edge functions to learn about what headers, and values are supported.


### Cloudflare Pages/Workers
Cloudflare Workers implements the Web Cache API. You can use a combination of a caching middleware, and `Cache-Control` headers.
  
```astro title="src/pages/index.astro"
---
// this header says: the browser and the cdn can store and reuse this page for 1 hour
Astro.response.headers.set('Cache-Control', 'max-age=3600')
---
<h1>Welcome to Astro</h1>
```
  
```ts title="src/middleware.ts"


const cachingMiddleware = async ({ request }, next) => {
    
    // caches.default is only available on cloudflare workers
    // other platforms implementing the Web Cache API require using the `open` method
    // `const cache = await caches.open("default")`
    const cache = caches.default

    const cachedResponse = await cache.match(request)
    
    // return the cached response if there was one
    if (cachedResponse) return cachedResponse
    
    else {
        // render a fresh response
        const response = await next()
        
        // add to cache
        await cache.put(request, response.clone())
        
        // return fresh response
        return response
    }
}

export const onRequest =
    // avoid using caches when it is not available. for example, when testing locally with node
    globalThis.caches instanceof globalThis.CacheStorage
        ? cachingMiddleware
        // a middleware that does nothing
        : (_, next) => next()
```

:::note
Cloudflare may remove the cached response from their server before the duration you set has elapsed. This may happen if the page was not receving visitors, or if the server is approaching capacity. If it is important to you that your visitors don't wait for the page to render afresh, you may be able to take advantage of Cloudflare's Cache Reserve feature, which stores cache on their object storage offering, R2.
:::